# üöó Previs√£o de Pre√ßos de Corridas (Uber & Lyft)
### <p align="center">Projeto de Regress√£o</p>

## Vis√£o Geral do Projeto
Este projeto constr√≥i um pipeline completo de Machine Learning para prever o pre√ßo de corridas de servi√ßos como Uber e Lyft, utilizando um dataset p√∫blico de Boston. O objetivo foi realizar uma an√°lise explorat√≥ria, aplicar t√©cnicas de engenharia de features e comparar m√∫ltiplos modelos de **Regress√£o** para encontrar a solu√ß√£o mais precisa para estimar o valor de uma corrida.

## üõ†Ô∏è Tecnologias Utilizadas
- **Linguagem:** Python
- **Bibliotecas:** Pandas, Scikit-learn, Matplotlib, Seaborn, Joblib

---

## üî¨ Pipeline do Projeto

#### 1. An√°lise Explorat√≥ria de Dados (EDA)
A investiga√ß√£o come√ßou com a an√°lise das features mais intuitivas.
- **Dist√¢ncia vs. Pre√ßo:** Um gr√°fico de dispers√£o mostrou que, apesar da correla√ß√£o positiva, a dist√¢ncia sozinha n√£o explica a grande varia√ß√£o nos pre√ßos.
- **Tipo de Servi√ßo vs. Pre√ßo:** Um boxplot revelou "degraus" de pre√ßos bem definidos entre os diferentes tipos de servi√ßo (ex: `Shared` vs. `Lux Black XL`), confirmando esta como uma feature fundamental.

![Gr√°fico de Dispers√£o de Dist√¢ncia vs. Pre√ßo][distancia_preco]
![Boxplot de Tipo de Servi√ßo vs. Pre√ßo][tiposervico_preco]

#### 2. Engenharia de Features
Para enriquecer o modelo, novas features foram criadas:
- **Features de Tempo:** A coluna `timestamp` foi convertida em vari√°veis mais √∫teis, como `hora`, `dia_da_semana` e `m√™s`. A an√°lise subsequente revelou padr√µes claros, como picos de pre√ßo nos hor√°rios de pico (8h e 17h).
- **Vari√°veis Categ√≥ricas:** Features de texto como `cab_type` e `name` foram transformadas em formato num√©rico usando **One-Hot Encoding** (`pd.get_dummies()`).

#### 3. Compara√ß√£o de M√∫ltiplos Modelos de Regress√£o
Com os dados preparados, foi realizado um "campeonato" entre tr√™s modelos de regress√£o para identificar o mais perform√°tico.
- **Regress√£o Linear**
- **Random Forest Regressor**
- **Gradient Boosting Regressor**

As m√©tricas de avalia√ß√£o utilizadas foram:
- **MAE (Erro M√©dio Absoluto):** O erro m√©dio da previs√£o em d√≥lares. Quanto menor, melhor.
- **R¬≤ (Coeficiente de Determina√ß√£o):** O poder explicativo do modelo. Quanto mais perto de 1 (100%), melhor.

---

## üìà Resultados e An√°lise

### Performance dos Modelos
A an√°lise comparativa mostrou a clara superioridade dos modelos baseados em √°rvores.

| Modelo | MAE (Erro M√©dio $) | R¬≤ Score |
| :--- | :--- | :--- |
| Regress√£o Linear | $1.77 | 0.927 |
| **Random Forest** | **$1.26** | 0.957 |
| Gradient Boosting | $1.28 | **0.959** |

Embora o Gradient Boosting tenha o maior R¬≤, o **Random Forest foi escolhido como o modelo final** por apresentar o **menor MAE**. Em um contexto de neg√≥cio, minimizar o erro m√©dio em d√≥lares √© uma m√©trica mais direta e interpret√°vel.

![Gr√°fico de Barras de MAE por Modelo][comparacao_mae]
![Gr√°fico de Barras de R¬≤ por Modelo][comparacao_r2]

---

## üöÄ Como Executar o Projeto

O projeto √© dividido em dois scripts principais para um fluxo de trabalho profissional:

1.  **`treinamento_e_analise.py`:** Executa todo o pipeline de EDA, limpeza, treinamento, compara√ß√£o e salva o modelo vencedor.
2.  **`predict.py`:** Carrega o modelo salvo e o utiliza para prever pre√ßos de novas corridas.

### Pr√©-requisitos
- Python 3.8+
- Bibliotecas listadas em `requirements.txt`

### Instala√ß√£o e Execu√ß√£o
1. Clone o reposit√≥rio: `git clone https://github.com/jampani1/ride-price-engine.git`
2. Instale as depend√™ncias: `pip install -r requirements.txt`
3. Execute o script de treinamento: `python treinamento_e_analise.py`
4. Execute o script de previs√£o para ver um exemplo: `python predict.py`

---

## üîÆ Melhorias Futuras
- **Engenharia de Features Geogr√°ficas:** Utilizar as colunas `source` e `destination` para criar features como dist√¢ncia do centro da cidade ou agrupamento por bairros.
- **Inclus√£o de Dados Clim√°ticos:** Aplicar t√©cnicas de "imputa√ß√£o" para preencher os dados clim√°ticos faltantes e testar seu impacto no modelo.
- **Otimiza√ß√£o de Hiperpar√¢metros:** Usar `GridSearchCV` para encontrar a combina√ß√£o √≥tima de par√¢metros para o Random Forest.

---

## üìÑ Fonte dos Dados
- **Dataset:** [Uber and Lyft Dataset Boston, MA](https://www.kaggle.com/datasets/brllrb/uber-and-lyft-dataset-boston-ma)

---

## üë®‚Äçüíª Conecte-se Comigo

Este projeto foi desenvolvido por mim, **Maur√≠cio J Souza**, como parte da minha jornada de aprendizado em ci√™ncia de dados e machine learning. Para considera√ß√µes, perguntas ou oportunidades, sinta-se √† vontade para me encontrar em:

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/mauriciojampani/)
[![GitHub](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/jampani1)
[![Gmail](https://img.shields.io/badge/Gmail-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:mmjampani13@gmail.com)

[distancia_preco]: imgs/distancia_preco.png
[tiposervico_preco]: imgs/tiposervico_preco.png
[comparacao_mae]: imgs/comparacao_modelos_regressao_mae.png
[comparacao_r2]: imgs/comparacao_modelos_regressao_r2.png
